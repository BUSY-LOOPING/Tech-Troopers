{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315af75-5d92-4c5d-a273-cc63bad047a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define columns for rolling statistics\n",
    "columns_for_rolling_stats = [\n",
    "    'Motor Speed (RPM)', 'Engine Speed (RPM)', 'Throttle (%)', 'Intake Temperature (C)',\n",
    "    'Engine Coolant Temperature 1 (C)', 'Barometric Pressure (kpa)', 'Fuel Trim',\n",
    "    'Fuel Consumption (g/min)', 'Expected BSFC (g/kW.hr)', 'Bus Voltage (V)',\n",
    "    'GCU Current (A)', 'Battery Current (A)', 'Power Generated (W)',\n",
    "    'Inverter Temperature (C)', 'Target Fuel Pressure (bar)', 'Fuel Pressure (bar)',\n",
    "    'Fuel Pump Speed (RPM)', 'Cooling Pump Speed (RPM)', 'Fans On (qty)', 'PWM Uptime (s)'\n",
    "]\n",
    "\n",
    "# Function to load and preprocess datasets\n",
    "def load_and_preprocess(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    # Ensure no duplicate columns\n",
    "    if data.columns.duplicated().any():\n",
    "        data = data.loc[:, ~data.columns.duplicated()]\n",
    "\n",
    "    # Rename timestamp column to 'Time (s)' if 'time (s)' exists\n",
    "    if 'time (s)' in data.columns and 'Time (s)' not in data.columns:\n",
    "        data.rename(columns={'time (s)': 'Time (s)'}, inplace=True)\n",
    "\n",
    "    # Sort by 'Time (s)' if it exists\n",
    "    if 'Time (s)' in data.columns:\n",
    "        data = data.sort_values('Time (s)')\n",
    "    \n",
    "    # Define rolling window size\n",
    "    window_size = 5\n",
    "\n",
    "    # Create rolling statistics\n",
    "    for column in columns_for_rolling_stats:\n",
    "        if column in data.columns:\n",
    "            data[f'{column}_rolling_mean'] = data[column].rolling(window=window_size).mean()\n",
    "            data[f'{column}_rolling_max'] = data[column].rolling(window=window_size).max()\n",
    "            data[f'{column}_rolling_min'] = data[column].rolling(window=window_size).min()\n",
    "            data[f'{column}_rolling_std'] = data[column].rolling(window=window_size).std()\n",
    "\n",
    "    # Replace negative values\n",
    "    negative_values_columns = ['Fuel Consumption (g/min)', 'GCU Current (A)', 'Power Generated (W)']\n",
    "    for column in negative_values_columns:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].clip(lower=0)\n",
    "\n",
    "    data.fillna(0, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to process each dataset individually\n",
    "def process_dataset(file):\n",
    "    # Load and preprocess the dataset\n",
    "    data = load_and_preprocess(file)\n",
    "    \n",
    "    # Define features for model training\n",
    "    features = [\n",
    "        'Motor Speed (RPM)', 'Engine Speed (RPM)', 'Throttle (%)', 'Intake Temperature (C)',\n",
    "        'Engine Coolant Temperature 1 (C)', 'Barometric Pressure (kpa)', 'Fuel Trim',\n",
    "        'Fuel Consumption (g/min)', 'Expected BSFC (g/kW.hr)', 'Bus Voltage (V)',\n",
    "        'GCU Current (A)', 'Battery Current (A)', 'Power Generated (W)',\n",
    "        'Inverter Temperature (C)', 'Target Fuel Pressure (bar)', 'Fuel Pressure (bar)',\n",
    "        'Fuel Pump Speed (RPM)', 'Cooling Pump Speed (RPM)', 'Fans On (qty)', 'PWM Uptime (s)'\n",
    "    ] + [f'{column}_rolling_mean' for column in columns_for_rolling_stats if f'{column}_rolling_mean' in data.columns]\n",
    "\n",
    "    # Ensure only columns that exist in data are used\n",
    "    features = [f for f in features if f in data.columns]\n",
    "\n",
    "    # Split data into training and testing sets (50% each)\n",
    "    train_data, test_data = train_test_split(data, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Train Isolation Forest on training data\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    isolation_forest.fit(train_data[features])\n",
    "    train_data['anomaly_score'] = isolation_forest.decision_function(train_data[features])\n",
    "    train_data['isolated_anomaly'] = isolation_forest.predict(train_data[features])\n",
    "    train_data['isolated_anomaly'] = train_data['isolated_anomaly'].map({1: 0, -1: 1})\n",
    "    \n",
    "    # Apply Isolation Forest on testing data\n",
    "    test_data['anomaly_score'] = isolation_forest.decision_function(test_data[features])\n",
    "    test_data['isolated_anomaly'] = isolation_forest.predict(test_data[features])\n",
    "    test_data['isolated_anomaly'] = test_data['isolated_anomaly'].map({1: 0, -1: 1})\n",
    "    \n",
    "    # Combine train and test data for clustering\n",
    "    combined_data = pd.concat([train_data, test_data])\n",
    "\n",
    "    # Apply KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    combined_data['cluster_anomaly'] = kmeans.fit_predict(combined_data[features])\n",
    "    \n",
    "    # Identify the larger cluster as normal and the smaller cluster as anomaly\n",
    "    normal_cluster_label = combined_data['cluster_anomaly'].value_counts().idxmax()\n",
    "    combined_data['cluster_anomaly'] = combined_data['cluster_anomaly'].apply(lambda x: 1 if x == normal_cluster_label else 0)\n",
    "    \n",
    "    # Separate back into train and test sets\n",
    "    train_data = combined_data.loc[train_data.index]\n",
    "    test_data = combined_data.loc[test_data.index]\n",
    "\n",
    "    # Label data as 'normal' or 'abnormal'\n",
    "    train_data['label'] = train_data.apply(lambda row: 'abnormal' if row['cluster_anomaly'] == 0 else 'normal', axis=1)\n",
    "    test_data['label'] = test_data.apply(lambda row: 'abnormal' if row['cluster_anomaly'] == 0 else 'normal', axis=1)\n",
    "    \n",
    "    # Save the results for the current dataset\n",
    "    result_file = f\"validated_anomalies_{file.split('/')[-1]}\"\n",
    "    test_data.to_csv(result_file, index=False)\n",
    "    \n",
    "    # Print the first few rows to verify\n",
    "    print(f\"Results for {file}:\")\n",
    "    print(test_data.head())\n",
    "    \n",
    "    # Plot Fuel Pump Speed (RPM) vs Fuel Consumption (g/min) for Isolation Forest anomalies\n",
    "    if 'Fuel Pump Speed (RPM)' in test_data.columns and 'Fuel Consumption (g/min)' in test_data.columns:\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.scatter(test_data['Fuel Pump Speed (RPM)'], test_data['Fuel Consumption (g/min)'], c=test_data['isolated_anomaly'], cmap='viridis', marker='o', label='Isolation Forest')\n",
    "        plt.xlabel('Fuel Pump Speed (RPM)')\n",
    "        plt.ylabel('Fuel Consumption (g/min)')\n",
    "        plt.title('Isolation Forest: Fuel Pump Speed (RPM) vs Fuel Consumption (g/min)')\n",
    "        plt.colorbar(label='Anomaly')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot Fuel Pump Speed (RPM) vs Fuel Consumption (g/min) for KMeans anomalies\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.scatter(test_data['Fuel Pump Speed (RPM)'], test_data['Fuel Consumption (g/min)'], c=test_data['cluster_anomaly'], cmap='viridis', marker='o', label='KMeans')\n",
    "        plt.xlabel('Fuel Pump Speed (RPM)')\n",
    "        plt.ylabel('Fuel Consumption (g/min)')\n",
    "        plt.title('KMeans: Fuel Pump Speed (RPM) vs Fuel Consumption (g/min)')\n",
    "        plt.colorbar(label='Anomaly')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Fetch all dataset files\n",
    "dataset_files = glob.glob('dataset_*.csv')\n",
    "for file in dataset_files:\n",
    "    process_dataset(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
